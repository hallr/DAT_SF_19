{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14 SVMs: Illuminating Advanced Classifiers\n",
    "\n",
    "Justin Breucop\n",
    "\n",
    "Today we'll cover Support Vector Machines: linear vs. rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMs\n",
    "\n",
    "Support vector machines are powerful tools for performing analysis, built on the theory that there is a higher dimension where data can be seperated (via an appropriate hyperplane for that dimension).\n",
    "\n",
    "As always, we'll import our standard packages, as well as two new ones: svm.SVC & tree.DecisionTreeClassifier. SVC stands for Support Vector Classification. There is an SVR class as well but that is for using SVMs in regression, which is out of scope for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "from bokeh.plotting import figure,show,output_notebook\n",
    "output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SVM can also be used for categorical data. Because SVMs are more complex than most classification algorithms we've seen, there are many more parameters to tune and options to set for the SVC. Sklearn SVC documentation:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "\n",
    "### Load the data!\n",
    "To demonstrate these classifiers clearly, we will use the Iris dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris_port = datasets.load_iris()\n",
    "iris = pd.DataFrame(iris_port.data,columns=iris_port.feature_names)\n",
    "y = iris_port.target\n",
    "X = iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = range(0,len(X))\n",
    "np.random.shuffle(index)\n",
    "train = index[:len(X)*3/5]\n",
    "test = index[len(X)*3/5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear',C=1).fit(X.iloc[train],y[train])\n",
    "print classification_report(y[test],model.predict(X.iloc[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear kernel has a coef\\_ attribute we can use to plot our features. The coefficients are provided in the order of the classifier target (row 1 corresponds to target 1, etc.)\n",
    "\n",
    "We'll be able to visually see how important each feature is to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = iris_port.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i,row in enumerate(model.coef_):\n",
    "    # Enumerate gives us a counter i for each value in model.coef_\n",
    "    # we use that to get the full name of the iris.\n",
    "    data[names[i]] = list(row)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar, show\n",
    "\n",
    "p=Bar(data, cat=list(iris.columns), title=\"SVC Feature Importance\",\n",
    "        xlabel='Flowers', ylabel='Linear Coefficient', width=600, height=600, legend=\"top_right\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Charts as Higher Level Glyph\n",
    "Bokeh has some default charting functions such as bar which intake data in a specific pattern to generate pretty charts in a small amount of code.\n",
    "\n",
    "There are more: http://bokeh.pydata.org/en/latest/docs/user_guide/charts.html#userguide-charts\n",
    "\n",
    "###End Aside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, Precision is only part of the story. Classification Report gives us a pretty full understanding of what's going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf',C=1).fit(X.iloc[train],y[train])\n",
    "print classification_report(y[test],model.predict(X.iloc[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Hands-on: Mushrooms!\n",
    "\n",
    "Today we'll be working with a mushroom dataset. If you're lost in a forest and find a gill capped mushroom and have access to your SVM classifier, you'll hopefully be prepared to see if it's poisonous! Humor aside, we'll see the power of an SVM working with a large number of attributes to separate two classes of data.\n",
    "\n",
    "The attributes are:\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s \n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s \n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y \n",
    "4. bruises?: bruises=t,no=f \n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s \n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n \n",
    "7. gill-spacing: close=c,crowded=w,distant=d \n",
    "8. gill-size: broad=b,narrow=n \n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y \n",
    "10. stalk-shape: enlarging=e,tapering=t \n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=? \n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
    "16. veil-type: partial=p,universal=u \n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y \n",
    "18. ring-number: none=n,one=o,two=t \n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z \n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y \n",
    "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y \n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: String Processing for Fun And Profit\n",
    "\n",
    "Because of the structure of the categories, I'm going to create a column:categories dictionary. First step is to put the data into a doc-string which is a special string defined by three apostrophes. The string accepts new lines and ends only when it sees another three apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributes = '''cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s \n",
    "cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s \n",
    "cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y \n",
    "bruises?: bruises=t,no=f \n",
    "odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s \n",
    "gill-attachment: attached=a,descending=d,free=f,notched=n \n",
    "gill-spacing: close=c,crowded=w,distant=d \n",
    "gill-size: broad=b,narrow=n \n",
    "gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y \n",
    "stalk-shape: enlarging=e,tapering=t \n",
    "stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=? \n",
    "stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
    "stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
    "stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
    "stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
    "veil-type: partial=p,universal=u \n",
    "veil-color: brown=n,orange=o,white=w,yellow=y \n",
    "ring-number: none=n,one=o,two=t \n",
    "ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z \n",
    "spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y \n",
    "population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y \n",
    "habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d'''\n",
    "attributes_list = attributes.split('\\n')\n",
    "attributes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ordered_attributes = []\n",
    "data_attributes = {}\n",
    "for att in attributes_list:\n",
    "    #Break our string into the column name and categories\n",
    "    col_data_split = att.split(': ')\n",
    "    #next, we split our category labels into a list of name=value\n",
    "    cat_labels = col_data_split[1].split(',')\n",
    "    \n",
    "    # lets now extract only our values (our data is pure letters) and value names. We'll do a \n",
    "    # dict comprehension that extracts the second value of a list after splitting on the =.\n",
    "    \n",
    "    #I split second on the spaces because there are some trailing spaces in my string\n",
    "    cats = {x.split('=')[1].split(' ')[0]:x.split('=')[0] for x in cat_labels}\n",
    "    #Now lets populate our columns dictionary defining a key, columns, and the values, our list\n",
    "    # called cats here\n",
    "    data_attributes[col_data_split[0]] = cats\n",
    "    \n",
    "    # we also want an ordered list to declare as the columns for our dataframe\n",
    "    ordered_attributes.append(col_data_split[0])\n",
    "\n",
    "\n",
    "data_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Aside\n",
    "\n",
    "So we have a dictionary of more verbose categories. We'll now want to apply them to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mush = pd.read_csv('../data/mushrooms.data',header=None,names=['edible?']+ordered_attributes)\n",
    "mush.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have verbose names for our data by using .map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in mush.columns:\n",
    "    if col == 'edible?':\n",
    "        continue\n",
    "    mush[col] = mush[col].map(data_attributes[col])\n",
    "mush.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the sheer # of attributes in this dataset, we will work with a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mush = mush[['edible?','cap-shape','cap-color','cap-surface']]\n",
    "mush.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now convert them into binary features using `pd.get_dummies` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.get_dummies(mush['cap-shape']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each new column, we'll preface it with the original column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mush_code = pd.DataFrame(mush['edible?'].map({'p':0,'e':1}))\n",
    "\n",
    "for column in mush.columns:\n",
    "    if column == 'edible?':\n",
    "        continue\n",
    "    temp = pd.get_dummies(mush[column],prefix=column)\n",
    "    mush_code[temp.columns] = temp\n",
    "mush_code.head()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, we've prepared our data. Now we need to provide it to an SVM Classifier and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X= mush_code.drop('edible?',axis=1)\n",
    "y = mush_code['edible?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest in showing a variety of approaches and flexing your coding skills, what is this code below doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = range(0,len(X))\n",
    "np.random.shuffle(index)\n",
    "train = index[:len(X)*4/5]\n",
    "test = index[len(X)*4/5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare two common kernels (note: the default kernel is rbf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SVC(C=1,kernel='linear').fit(X.iloc[train],y.iloc[train])\n",
    "print classification_report(y.iloc[test],model.predict(X.iloc[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SVC(C=1,kernel='rbf').fit(X.iloc[train],y.iloc[train])\n",
    "print classification_report(y.iloc[test],model.predict(X.iloc[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Exercise 1\n",
    "Convert one column to a dummy encoder and add the 'edible?' column to it. Train a linear kernel on it and generate a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Exercise 2\n",
    "Plot the coefficients for the columns. Is this surprising? Share the results with your neighbor and identify the category of your column that best identifies an edible mushroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Train your SVM on every single category! What would you expect the score to do? (Hint: take your process for Exercise 1 and apply it to every column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Cross validate an SVC model. Remember cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Old Dog, New Data\n",
    "Utilize the mushroom dataset and train a Decision Tree on it. Are you overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Topic: Kernel Play\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_svm_kernels.html\n",
    "\n",
    "What kernel performs best for the mushroom data? Do we know why? (the kernels shown are 'linear', 'poly' and 'rbf' however there are many others you can see in the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
